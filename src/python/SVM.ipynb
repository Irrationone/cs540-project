{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "Blah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "train = pd.DataFrame.from_csv('../../train.csv')\n",
    "test = pd.DataFrame.from_csv('../../test.csv')\n",
    "\n",
    "## Dimensions of train set\n",
    "ntrain,dtrain = train.shape\n",
    "\n",
    "## Dimensions of test set\n",
    "ntest, dtest = test.shape\n",
    "\n",
    "X = train.drop(['TARGET'], axis=1)\n",
    "\n",
    "## Add a column that tells us how many 0's we have\n",
    "X['n0'] = (X == 0).sum(axis=1)\n",
    "\n",
    "Xtest = test\n",
    "Xtest['n0'] = (Xtest == 0).sum(axis=1)\n",
    "\n",
    "## Standardize sets together\n",
    "def standardize_sets(X, Xtest):\n",
    "    Xtotal = X.append(Xtest)\n",
    "    Xtotal_scaled = preprocessing.scale(Xtotal)\n",
    "    X_scaled,Xtest_scaled = np.split(Xtotal_scaled, [ntrain])\n",
    "    return [X_scaled, Xtest_scaled]\n",
    "\n",
    "targets = np.array(train.TARGET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.feature_selection import f_classif,chi2\n",
    "from sklearn.preprocessing import Binarizer, scale\n",
    "\n",
    "## Top 75th percentile\n",
    "p = 75\n",
    "y = targets\n",
    "\n",
    "X_bin = Binarizer().fit_transform(scale(X))\n",
    "selectChi2 = SelectPercentile(chi2, percentile=p).fit(X_bin, y)\n",
    "selectF_classif = SelectPercentile(f_classif, percentile=p).fit(X, y)\n",
    "\n",
    "chi2_selected = selectChi2.get_support()\n",
    "chi2_selected_features = [ f for i,f in enumerate(X.columns) if chi2_selected[i]]\n",
    "f_classif_selected = selectF_classif.get_support()\n",
    "f_classif_selected_features = [ f for i,f in enumerate(X.columns) if f_classif_selected[i]]\n",
    "selected = chi2_selected & f_classif_selected\n",
    "features = [ f for f,s in zip(X.columns, selected) if s]\n",
    "\n",
    "## Number of features selected\n",
    "print(len(features))\n",
    "\n",
    "X_selected = X[features]\n",
    "Xtest_selected = Xtest[features]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_selected,Xtest_selected = standardize_sets(X_selected, Xtest_selected)\n",
    "Xs2, Xt2 = standardize_sets(X, Xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45612, 261)\n",
      "(30408, 261)\n",
      "(45612, 370)\n",
      "(30408, 370)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import cross_validation\n",
    "\n",
    "sss = cross_validation.StratifiedShuffleSplit(targets, 1, test_size=0.4, random_state=4224)\n",
    "(train_index,valid_index) = list(sss)[0]\n",
    "\n",
    "X_train = X_selected[train_index,]\n",
    "X_valid = X_selected[valid_index,]\n",
    "y_train = targets[train_index]\n",
    "y_valid = targets[valid_index]\n",
    "\n",
    "X_train2 = Xs2[train_index,]\n",
    "X_valid2 = Xs2[valid_index,]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(X_train2.shape)\n",
    "print(X_valid2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training accuracy:', 0.96016399193194768)\n",
      "('Validation accuracy:', 0.96024072612470401)\n",
      "('Training AUC:', 0.8026358693607385)\n",
      "('Validation AUC:', 0.79568686569827785)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "logreg = LogisticRegression(penalty='l1', dual=False, max_iter=100, C=2)\n",
    "logreg.fit(X_train2, y_train)\n",
    "\n",
    "y_hat = logreg.predict_proba(X_valid2)\n",
    "y_hat2 = logreg.predict_proba(X_train2)\n",
    "print(\"Training accuracy:\",logreg.score(X_train2, y_train))\n",
    "print(\"Validation accuracy:\",logreg.score(X_valid2, y_valid))\n",
    "print(\"Training AUC:\",roc_auc_score(y_train, y_hat2[:,1]))\n",
    "print(\"Validation AUC:\",roc_auc_score(y_valid, y_hat[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[176]\n",
      "(1, 370)\n",
      "370\n",
      "[0, 1, 2, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 23, 24, 27, 28, 30, 34, 35, 39, 42, 43, 44, 45, 46, 49, 52, 54, 55, 60, 62, 63, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 88, 89, 90, 91, 93, 94, 97, 107, 109, 110, 111, 113, 114, 117, 118, 119, 120, 121, 123, 128, 129, 135, 139, 141, 142, 145, 146, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 164, 166, 168, 172, 178, 184, 187, 188, 190, 191, 193, 194, 195, 196, 197, 199, 200, 201, 207, 208, 209, 211, 212, 213, 219, 224, 225, 231, 235, 240, 241, 253, 255, 256, 257, 258, 259, 260, 263, 264, 270, 272, 273, 274, 276, 277, 279, 280, 281, 282, 283, 286, 289, 290, 291, 294, 295, 297, 298, 300, 301, 302, 304, 309, 310, 311, 312, 323, 324, 326, 328, 329, 330, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 348, 364, 366, 368, 369]\n"
     ]
    }
   ],
   "source": [
    "print((logreg.coef_ != 0).sum(axis=1))\n",
    "print((logreg.coef_.shape))\n",
    "print(len(logreg.coef_[0]))\n",
    "print([i for i in range(len(logreg.coef_[0])) if logreg.coef_[0][i] != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45612, 176)\n",
      "(30408, 176)\n"
     ]
    }
   ],
   "source": [
    "l1features = [0, 1, 2, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 23, 24, 27, 28, 30, 34, 35, 39, 42, 43, 44, 45, 46, 49, 52, 54, 55, 60, 62, 63, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 88, 89, 90, 91, 93, 94, 97, 107, 109, 110, 111, 113, 114, 117, 118, 119, 120, 121, 123, 128, 129, 135, 139, 141, 142, 145, 146, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 164, 166, 168, 172, 178, 184, 187, 188, 190, 191, 193, 194, 195, 196, 197, 199, 200, 201, 207, 208, 209, 211, 212, 213, 219, 224, 225, 231, 235, 240, 241, 253, 255, 256, 257, 258, 259, 260, 263, 264, 270, 272, 273, 274, 276, 277, 279, 280, 281, 282, 283, 286, 289, 290, 291, 294, 295, 297, 298, 300, 301, 302, 304, 309, 310, 311, 312, 323, 324, 326, 328, 329, 330, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 348, 364, 366, 368, 369]\n",
    "X_train3 = X_train2[:,l1features]\n",
    "X_valid3 = X_valid2[:,l1features]\n",
    "print(X_train3.shape)\n",
    "print(X_valid3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the thing (Linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'probability'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-d5885d5cd3c5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msvm\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mlin_clf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinearSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdual\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"balanced\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprobability\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mlin_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'probability'"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "lin_clf = svm.LinearSVC(dual=True, class_weight=\"balanced\")\n",
    "lin_clf.fit(X_train3, y_train)\n",
    "\n",
    "y_hat = lin_clf.predict_proba(X_valid3)\n",
    "y_hat2 = lin_clf.predict_proba(X_train3)\n",
    "print(\"Training accuracy:\",lin_clf.score(X_train3, y_train))\n",
    "print(\"Validation accuracy:\",lin_clf.score(X_valid3, y_valid))\n",
    "print(\"Training AUC:\",roc_auc_score(y_train, y_hat2))\n",
    "print(\"Validation AUC:\",roc_auc_score(y_valid, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Validation AUC:', 0.7153391132680198)\n"
     ]
    }
   ],
   "source": [
    "preds = 1./(1.+np.exp(-y_hat))\n",
    "y_hatp = np.vstack((1-preds, preds)).T\n",
    "print(\"Validation AUC:\",roc_auc_score(y_valid, y_hatp[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the thing (Polynomial kernel)\n",
    "This takes almost forever to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training accuracy:', 0.75291589932473912)\n",
      "('Validation accuracy:', 0.74667850565640626)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "bad input shape (45612, 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-1538bc2bbade>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Training accuracy:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Validation accuracy:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_valid3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Training AUC:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_hat2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Validation AUC:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_hat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/carolyn/anaconda2/lib/python2.7/site-packages/sklearn/metrics/ranking.pyc\u001b[0m in \u001b[0;36mroc_auc_score\u001b[1;34m(y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[0;32m    255\u001b[0m     return _average_binary_score(\n\u001b[0;32m    256\u001b[0m         \u001b[0m_binary_roc_auc_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m         sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/carolyn/anaconda2/lib/python2.7/site-packages/sklearn/metrics/base.pyc\u001b[0m in \u001b[0;36m_average_binary_score\u001b[1;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mbinary_metric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/carolyn/anaconda2/lib/python2.7/site-packages/sklearn/metrics/ranking.pyc\u001b[0m in \u001b[0;36m_binary_roc_auc_score\u001b[1;34m(y_true, y_score, sample_weight)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         fpr, tpr, tresholds = roc_curve(y_true, y_score,\n\u001b[1;32m--> 252\u001b[1;33m                                         sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    253\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mauc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreorder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/carolyn/anaconda2/lib/python2.7/site-packages/sklearn/metrics/ranking.pyc\u001b[0m in \u001b[0;36mroc_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \"\"\"\n\u001b[0;32m    500\u001b[0m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[1;32m--> 501\u001b[1;33m         y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m     \u001b[1;31m# Attempt to drop thresholds corresponding to points in between and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/carolyn/anaconda2/lib/python2.7/site-packages/sklearn/metrics/ranking.pyc\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[0;32m    294\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m     \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m     \u001b[0my_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m         \u001b[0msample_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/carolyn/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[1;34m(y, warn)\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 551\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"bad input shape {0}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    552\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: bad input shape (45612, 2)"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "clfp = svm.SVC(kernel=\"poly\", degree=3, class_weight=\"balanced\", probability=True)\n",
    "clfp.fit(X_train3, y_train)\n",
    "\n",
    "y_hat = clfp.predict_proba(X_valid3)\n",
    "y_hat2 = clfp.predict_proba(X_train3)\n",
    "print(\"Training accuracy:\",clfp.score(X_train3, y_train))\n",
    "print(\"Validation accuracy:\",clfp.score(X_valid3, y_valid))\n",
    "print(\"Training AUC:\",roc_auc_score(y_train, y_hat2))\n",
    "print(\"Validation AUC:\",roc_auc_score(y_valid, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training AUC:', 0.83513594350236964)\n",
      "('Validation AUC:', 0.75357108854298094)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Training AUC:\",roc_auc_score(y_train, y_hat2[:,1]))\n",
    "\n",
    "print(\"Validation AUC:\",roc_auc_score(y_valid, y_hat[:,1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the thing (RBF kernel)\n",
    "This also takes almost forever to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training accuracy:', 0.70057221783741119)\n",
      "('Validation accuracy:', 0.69060773480662985)\n",
      "('Training AUC:', 0.75684607177485153)\n",
      "('Validation AUC:', 0.68205056331881908)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "clfp = svm.SVC(kernel=\"rbf\", class_weight=\"balanced\")\n",
    "clfp.fit(X_train, y_train)\n",
    "\n",
    "y_hat = clfp.predict(X_valid)\n",
    "y_hat2 = clfp.predict(X_train)\n",
    "print(\"Training accuracy:\",clfp.score(X_train, y_train))\n",
    "print(\"Validation accuracy:\",clfp.score(X_valid, y_valid))\n",
    "print(\"Training AUC:\",roc_auc_score(y_train, y_hat2))\n",
    "print(\"Validation AUC:\",roc_auc_score(y_valid, y_hat))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
